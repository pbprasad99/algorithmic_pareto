{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"algorithmic_pareto","text":"<p>[WIP]  Algorithms and Data Structures - The Pareto Set</p> <p>The absolute basics to master.</p>"},{"location":"#philosophy","title":"philosophy","text":"<p>Broadly, I classify any algorithm or data structure into recursive or iterative. Of course, this is not a strict demarcation, but only in terms of the usual implementations.</p> <p>As for data structures, there are two fundamental types in terms of how they are stored : contiguous storage (arrays, dynamic arrays) and linked storage (linked lists, trees, graphs) </p>"},{"location":"#mental-models","title":"mental models","text":"<p>To effectively use a concept, it helps greatly to have the right mental model which allows you to use it in a consistent manner.</p> <p>For example, understanding and thinking of binary search in terms of bisect left and bisect right makes it easy to actually use it in a consistent manner.</p> <p>Another example, for array partitioning, just thinking of and  defining the loop invariant correctly is key. </p> <p>My effort is always to develop the correct understanding and mental model for any concept.</p>"},{"location":"#call-a-thing-by-its-right-name","title":"call a thing by its right name","text":"<p>Just knowing the name of a thing is very powerful.  Know the name of the problem and know the name of the algorithm.</p>"},{"location":"#index","title":"index","text":"<ul> <li>.github</li> <li>workflows</li> <li>docs</li> <li>assets<ul> <li>css</li> <li>images</li> </ul> </li> <li>iterative<ul> <li>1_array_partitioning</li> <li>2_binary_search</li> <li>problems<ul> <li>median_of_two_sorted_arrays</li> </ul> </li> </ul> </li> <li>iterative</li> <li>1_array_partitioning<ul> <li>1_two_way_partition</li> <li>1_Hoare</li> <li>2_Lomuto</li> <li>2_three_way_partition</li> <li>Djikstra</li> <li>3_quick_select</li> </ul> </li> <li>2_binary_search<ul> <li>problems</li> <li>median_of_two_sorted_arrays</li> </ul> </li> <li>recursive</li> <li>1_basics</li> <li>2_backtracking</li> </ul>"},{"location":"#algorithm-categories","title":"Algorithm Categories","text":"<p>This repository contains implementations and explanations of various algorithms categorized by approach:</p> <ul> <li>Iterative: Algorithms that use loops and iterations</li> <li>Recursive: Algorithms that call themselves to solve subproblems</li> <li>Dynamic Programming: Algorithms that break down problems into simpler subproblems</li> <li>Greedy: Algorithms that make locally optimal choices at each step</li> </ul>"},{"location":"#how-to-use-this-resource","title":"How to Use This Resource","text":"<p>Navigate through the sections to find detailed explanations, implementations, and complexity analysis for each algorithm.</p>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/1_Hoare/","title":"Defining the problem","text":"<p>Let us consider the simplest version of the problem.</p> <p>Given an array of integers, rearrange the elements such that the left part contains elements less than or equal to a pivot value and the right part contains values greater than the pivot value.</p>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/1_Hoare/#the-algorithm-hoare-partition-with-strict-condition","title":"The algorithm - Hoare partition with strict condition","text":"<p>Consider this example array and a pivot value of 4   :</p> <p>[ 1 , 9, 3, 5, 7, 4, 8  ]</p> <p>If this array were already partitioned s.t. the left partition has only elements less than or equal to the pivot. These would hold true : <pre><code>Any element in left partition &lt;= pivot\nAny element in right partition &gt; pivot\n</code></pre> If we take left and right pointers  while verifying that arr[left] &lt;= pivot and arr[right] &gt; pivot, left and right pointers would move past each other before evaluating to False for the first time. Left pointer would end up at the BEGINNING of the right partition and the right pointer would end up at the END of the left partition.</p> <pre><code>[ 1,   3,     4,   5,   7,   8,   9 ]\n  L/T  L/T   L/T *L/F*                            # L = Left pointer, T = arr[left]&lt;= pivot is True , F = Its False\n            *R/F* R/T   R/T     R/T    R/T        # R = right pointer, T = arr[right] &gt; pivot is True, F = Its False   \n</code></pre> <p>If left evaluates to True while its less than right, it would mean that this element is in the wrong partition. This also implies that there must be an element in the right partition which belongs to the left partition. </p> <pre><code>[  1 ,   9,   3,   5,   7,   4,   8  ]         \n  L/T **L/F**                                    # L = Left pointer, T = arr[left]&lt;= pivot is True, F = Its False\n                          **R/F**   R/T          # R = right pointer, T = arr[right] &gt; pivot is True, F = Its False                \n</code></pre> <p>We can simply swap these and keep moving until left and right pass each other.</p> <p>So, the algorithm would be:</p> <pre><code>Invariant 1) [0,right] only contains elements less than or equal to pivot\nInvariant 2) (right, len(arr) -1] only contains elements greater than pivot\n\n\nWhile left &lt;= right :\n      while left&lt;=right and &gt; (Invaraint 1) is True :\n           left +=1\n      while left&lt;=right and (Invariant 2) is True :\n           right -=1\n      if left &lt; right :\n          swap left and right\nreturn right\n</code></pre>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/1_Hoare/#the-algorithm-hoare-partition-with-weak-condition","title":"The algorithm - Hoare partition with weak condition","text":"<p>The problem with the partition scheme with a strict condition (where we always put pivot values  in one of the partitions) is that it produces unbalanced partitions when used in quickselect or quicksort.</p> <p>Consider if the above partition scheme were used in quickselect for finding the smallest element in an array of size n). </p> <p>What happens when all elements are duplicates :</p> <p><pre><code>    [1,1,1,1,1,1]\n     l         r   Iter 1 : 5  comparisons\n     l       r     Iter 2 : 4  comparisons\n     l     r       Iter 3 : 3  comparisons\n     l   r         Iter 4 : 2  comparisons\n     l r           Iter 5 : 1  comparisons\n     lr            Iter 6 : 0  comparisons\n</code></pre> Number of comparisons = SUM([1.....n]) = n(n+1)/2 = (n*2 + n ) /2 Therefore, Complexity is O(n^2)  in this case.</p> <p>To mitigate this, we could slightly modify the definition of our partitions :</p> <pre><code>Any element in left partition &lt;= pivot\nAny element in right partition &gt;= pivot\n</code></pre> <p>Invariant 1) [low,right] only contains elements less than OR EQUAL to pivot Invariant 2) (right, high] only contains elements greater OR EQUAL to pivot</p> <p>That is, pivot values are allowed to be in either partition.</p> <p>Our problem now becomes : </p> <p>Given an array of integers, rearrange the elements such that the left part contains elements less than or equal to a pivot value and the right part contains values greater than or equal to the pivot value.</p> <p>The implementation is tricky when handling values equal to pivot. </p> <p>We also stop scanning when left or right are equal to pivot in both partitions.  We swap and move the left and right pointers. After any swap, both partitions will increase by 1. Pivot values might end up in any partition.  This will also be the case when, left and right are both pointing to pivot value i.e. both partitions increase by 1 and there is a redundant swap between two pivot values.</p> <pre><code>While left &lt;= right :\n      while  left&lt;=right and left &lt; pivot :\n           left +=1\n      while left&lt;=right and right &gt; pivot:\n           right -=1\n      if left &lt;= right :\n          swap left and right\n          left-=1\n          right-=1\nreturn right\n</code></pre> <p>Let us see the behavior of quickselect with this scheme for the same case :</p> <pre><code>    [1,1,1,1,1,1]\n     l         r   Iter 1 : 5  comparisons\n     l   r         Iter 2 : 3  comparisons; This iteration returns r=0 and ends the loop\n     rl            Iter 2 END \n</code></pre> <p>The complexity is reduced to nLOG(n) now.</p>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/1_Hoare/#important-things-to-note","title":"Important things to Note:","text":"<p>This algorithm does not necessarily place the pivot in its sorted position. Or rather, the problem is not asking us to do this,</p> <p>This array is partitioned by 4 but 4 is not in its sorted position.</p> <pre><code>[ 1,   4,    3,  |5,   7,   8,   9 ]\n</code></pre> <p>We can put the pivot in its sorted position by swapping it with the right pointer after running the algorithm.  A good way to handle this is : 1) Ensure that  the pivot at the lowest index  . 2) Run the partitioning algorithm on the rest of the array. 3) Swap right with low.</p> <p>But again, this will not group multiple instances of pivot together if pivot is duplicated. That is another problem called three way partitioning.</p> <p>This algorithm is not stable. The relative order of elements will not be preserved. Naive partitioning using extra space is the only algorithm which preserves relative order of elements.</p> <p>Additional References : https://algs4.cs.princeton.edu/23quicksort/</p>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/2_Lomuto/","title":"Defining the problem","text":"<p>Let us consider the simplaest case, that of an array of integers.</p> <p>Given an array of integers, rearrange the elements such that the left part contains elements less than or equal to a pivot value and the right part contains values greater than the pivot value.</p>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/2_Lomuto/#the-algorithm","title":"The Algorithm","text":"<p>The Lomuto partition fixes uses two forward iterators to maintains two invariants :</p> <p>[lo,s) contains only elements less than or equal to the pivot.  # Left closed Right open interval</p> <p>[s,f) contains elements larger than the pivot.      # Left closed right open interval</p> <p>Usually, pivot is fixed at hi. </p> <p>Initial conditions are :</p> <p>s, f = 0,0</p> <p>Both invariants are trivially true initially.</p> <p>During execution :</p> <pre><code>[---&lt;=pivot----|---&gt;pivot------|---Unexamined---|pivot] \nlo              s               f                    hi \n</code></pre> <p>s and f can be thought of as slow and fast pointers with s at the write position and f at the read position.</p> <p>The algorithm is </p> <pre><code>def partition(arr,lo,hi) :\n    s = lo\n    pivot = arr[hi]\n    for f in range(lo,hi+1) : \n         if arr[f] &lt;= pivot : \n              arr[s],arr[f] = arr[f],arr[s] #swap s and f\n              s+=1\n    return s-1      \n</code></pre> <p>Since [s,f] is a half closed interval, it is empty if  s and f are equal. If there is a gap, this interval is gauranteed to only contain elements greater than pivot, since a gap INCREASES as a result of f pointing to a value less than or equal to the pivot and s pointing to a value greater than pivot,  in the first place.</p> <p>Dry Run :</p> <pre><code>General case :\n     [ 1,  4,  7,  3,  1,  4 ]\n0      sf                      # Initial condition, pivot = 4, arr[f] &lt;= 4 is True,  s will be swapped with f and both will move ahead\n1          sf                  # arr[f] &lt;= 4 , swap s with f and move both ahead\n2              sf              # arr[f] &lt;=4 is False, s stays where it is and only f moves ahead\n3              s  f            # arr[f] &lt;=4 is True, swap s with f and move both ahead\n4    [ 1,  4,  3,  7,  1,  4 ]\n                   s   f       # arr[f] &lt;=4 is True, swap s with f and move both ahead\n5    [ 1,  4,  3,  1,  7,  4 ] # arr[f] &lt;=4 is True, swap s with f and move both ahead\n                       s   f\n6    [ 1,  4,  3,  1,  4,  7 ] # arr[f] &lt;=4 is True, swap s with f and move both ahead\n                           s   # For loop ends\nReturn s -1\n\nOnly one element :\n  [4]\n0  sf      #arr[f] &lt;= f is True, swap s with f and move both ahead\n1    sf\nReturn s-1\n\nSorted array \n  [1,2,3]\n0  sf           \n1    sf\n2      sf\n3        s\n\nreturn s-1\n\nReverse sorted array :\n  [ 3, 2, 1 ]\n0   sf               #Initial conditions, arr[s] &lt;= 1 is False, only f will move ahead\n1   s  f             #arr[s] &lt;= 1 is False, only f will move ahead          \n2   s     f          #arr[s] &lt;= 1 is True, s and f will be swapped and both will move ahead \n3 [ 1, 2, 3 ]\n       s     f       #for loop ends\nreturn s -1 \n\nReverse sorted array with duplicate keys:\n[3, 2 ,1, 1]\n s     f\n[1, 2 ,3, 1]\n    s     f\n[1, 1 ,3, 2]\n       s     f   # for loop ends, \nreturn s-1 \n\nDuplicate keys :\n[1 , 1, 1, 1]\n             sf\nreturn s-1\n</code></pre>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/2_Lomuto/#variant-implementation","title":"Variant Implementation","text":"<p>We could redefine our problem statement slightly : Given an array of integers, rearrange the elements such that the left part contains elements less than or equal to a pivot value and the right part contains values greater than the pivot value.</p> <p>[lo,s) only contains elements strictly less than pivot [s,f)  contains elements equal to or greater than pivot.</p> <p>Initial conditions are :</p> <p>s, f = 0,0</p> <p>Both invariants are trivially true initially.</p> <p>During execution :</p> <p><pre><code>[---&lt;=pivot----|---&gt;pivot------|---Unexamined---|pivot] \nlo              s               f                    hi \n</code></pre> The algorithm is </p> <pre><code>def partition(arr,lo,hi) :\n    s = lo\n    pivot = arr[hi]\n    # The range might as well be range(lo,hi+1). It would make no difference except one extra redundant comparsion.\n    for f in range(lo,hi) : \n         if arr[f] &lt; pivot : \n              arr[s],arr[f] = arr[f],arr[s] #swap s and f\n              s+=1\n    arr[s],arr[hi] = arr[hi],arr[s]\n    return s      \n</code></pre> <p>When for loop exits, s is positioned at the sorted position of pivot. We swap pivot with s and return s.</p> <pre><code>[ 1,  4,  7,  3,  1,  4 ]\n      s       f             # arr[f] &lt; pivot is True, s and f will be swapped and both will move ahead.\n[ 1,  3,  7,  4,  1,  4 ]    \n          s       f\n[ 1,  3,  1,  4,  7,  4 ]\n              s       f\n[ 1,  3,  1,  4,  7,  4 ]\n                  s       f  # for loop ends\n[ 1,  3,  1,  4,  4,  7 ]\n                  s       f  # FInally Swap s with f\nReturn s \n\n\nReverse sorted array :\n  [ 3, 2, 1 ]\n    s        f \n  [ 1, 2, 3 ]\n    s        f\nreturn s\n\nReverse sorted array with duplicate keys:\n[3, 2 ,1, 1]\n s          f\n\nreturn s \n\nDuplicate keys :\n1  1  1  1 \ns          f #swap s[0] with s[-1]\nreturn s \n</code></pre> <p>The two implementations behave differently when it comes to duplicate keys :</p> <p>The first implementation puts one instance of the pivot value in the LAST sorted position. The second implementation puts one instance of the pivot value in the FIRST sorted position.</p>"},{"location":"iterative/1_array_partitioning/1_two_way_partition/2_Lomuto/#additional-resources","title":"Additional Resources","text":"<p>https://www.cs.virginia.edu/~horton/cs4102/page4/files/06-ch6-sorting.ppt.pdf</p> <p>https://iq.opengenus.org/lomuto-partition-scheme/</p> <p>https://www.stepanovpapers.com/PAM3-partition_notes.pdf</p> <p>https://dlang.org/blog/2020/05/14/lomutos-comeback/</p> <p>https://nicholasvadivelu.com/2021/01/11/array-partition/</p> <p>https://cs-notes.gitbook.io/algorithm-notes/outline/overview-2/quick-sort</p>"},{"location":"iterative/1_array_partitioning/2_three_way_partition/Djikstra/","title":"Index","text":"<p>Coming Soon</p>"},{"location":"iterative/1_array_partitioning/3_quick_select/","title":"Quickselect and Quicksort","text":""},{"location":"iterative/1_array_partitioning/3_quick_select/#quickselect","title":"QuickSelect","text":""},{"location":"iterative/1_array_partitioning/3_quick_select/#defining-the-problem","title":"Defining the problem.","text":"<p>Given an array, find the sorted value in non decreasing order at the kth smallest index when indices are counted from zero.</p>"},{"location":"iterative/1_array_partitioning/3_quick_select/#the-algorithm","title":"The Algorithm","text":"<p>The core of the quickselect algorithm is the partitioning scheme. There are different ways of implementing quickselet based on whether the partitioning scheme puts the pivot in its sorted position or not. Here we will consider only the implementation which uses partition schemes which do, becuase this is simpler and more intuitive.</p> <p>Assume, you have a partitioning scheme which returns some partition index / pivot index s.t. the value at the pivot index is in its sorted position. The quickeselect algorithm makes one recursive call based on the relative position of k to the pivot index. The base case is when the pivot index is k.</p> <p>The algorithm is :</p> <pre><code>def quickselect(arr,lo,hi, k ) :\n    p = partition(arr,lo,hi)\n    if p == k :\n       return arr[k]\n    elif  k&lt; p :\n       return quickselect(arr,lo,p-1,k)\n    else :\n       return quickselect(arr,p+1,hi,k)\n</code></pre>"},{"location":"iterative/1_array_partitioning/3_quick_select/#additional-references","title":"Additional References :","text":"<p>https://en.wikipedia.org/wiki/Selection_algorithm</p>"},{"location":"iterative/1_array_partitioning/3_quick_select/#quicksort","title":"QuickSort","text":""},{"location":"iterative/1_array_partitioning/3_quick_select/#defining-the-problem_1","title":"Defining the problem.","text":"<p>GIven an array, sort it in non decreasing order.</p>"},{"location":"iterative/1_array_partitioning/3_quick_select/#the-algorithm_1","title":"The Algorithm","text":"<p>Once you understand partitioning, quickselect and quicksort are just recursive applications of it. In quickselect, we make a single recursive call, while in quicksort, we make two recursive calls to eventually put all elements in their sorted position. Quick Sort can be visualized as a preorder traversal of a binary tree, where in the preorder position, you call the partitioning function and recursively call quicksort on both partitions. The base case is when lo &gt;= hi.</p> <p>Assume, you have a partitioning scheme which returns some partition index / pivot index s.t. the value at the pivot index is in its sorted position.</p> <p>The algorithm is :</p> <pre><code>def quicksort(arr,lo,hi, k ) :\n    if lo &gt;= hi  :\n       return \n    p = partition(arr,lo,hi)\n    quicksort(arr,lo,p-1,k)\n    quicksort(arr,p+1,hi,k)\n</code></pre>"},{"location":"iterative/1_array_partitioning/3_quick_select/#additional-references_1","title":"Additional References :","text":"<p>https://algs4.cs.princeton.edu/23quicksort/</p>"},{"location":"iterative/2_binary_search/","title":"Index","text":"<p>Coming soon</p>"},{"location":"iterative/2_binary_search/problems/median_of_two_sorted_arrays/LC_4__median_of_two_sorted_arrays/","title":"What is the data?","text":"<p>nums1 = [1,2], nums2 = [3,4]</p> <p>Two sorted arrays.</p>"},{"location":"iterative/2_binary_search/problems/median_of_two_sorted_arrays/LC_4__median_of_two_sorted_arrays/#what-is-being-asked","title":"What is being asked?","text":"<p>To find the median in logarithmic time.</p>"},{"location":"iterative/2_binary_search/problems/median_of_two_sorted_arrays/LC_4__median_of_two_sorted_arrays/#thoughts","title":"Thoughts","text":"<p>What is a median</p> <p>Consider : <pre><code>[1 2 |3 4]  #right partition is inclusive \n</code></pre> If we partition an even lengthed sorted array such that the left and right partitions are of equal size.</p> <p>The median is ( max(left partition) + min(right partition)  ) / 2</p> <p>If the array is odd lengthed : <pre><code>[1 2 3 4 5]\n     *\n</code></pre> We can consider the middle element to belong to both partitions. In which case <pre><code>[1 2 3 4 5]\n     *\n</code></pre></p> <p>The middle element IS the median i.e. index len(arr)//2</p> <p>We can always find partitions on A and B such that elements to the left of both partitions are less than elements to their right.</p> <pre><code>Example 1: \nB [ 1, 2, |6, 7]  # right pertition is inclusive\nA  [  5, |10  ]\n\n1,2,5  &lt; 6,7,10\n</code></pre> <pre><code>Example 2 :\nB [ |5, 6, 7, 8, 9 ] # consider left out of bounds position to be -inf and right out of bounds position to be +inf\n\nA [ 1, 2, 3, 4| ]\n\n1,2,3,4 &lt; 5,6,7,8,9\n</code></pre> <p>If we find the correct partitions like this, we can calculate the mean,</p> <p>The first question is how should we define the partitions?</p> <p>partition_a + partition_b = (m+n+1) //2 OR partition_a + partition_b = (m+n) // 2 </p> <p>let len(A) =m and len(B) = n </p> <p>FOR ODD LENGTHED ARRAY :</p> <pre><code>B  [1]   ; #IFF partition_b = (m+n +1 )//2 - partition_a  = 2//2 -0 = 1 But *IFF partition_b =  (m+n)//2 - partition_a =  1//2 -0 = 0-0 = 0 \n   *0 #1  \nA  [ ]   ; partition_a = (0+ 0)//2 =0 \n    0\n</code></pre> <p>If we say that partition_x + partition_y = (m+n)//2 then median is in the right partition in case of odd lengthed array.</p> <p>If we say that partition_x + partition_y = (m+n+1)//2 then median is in the left partition in case of odd lenghted array.</p> <p>It makes no difference for arrays where m+n is even. <pre><code>B [1 2]   ; #IFF partition_b = (m+n+1)//2 - partition_a  = 5//2 - 1 = 2- 1 = 1 and *IFF partition_b = (m+n)//2 - partition_a = 4//2 -1 = 1\n    #*1\nA [1 2]   ; partition_a = (0 + 2) // 2 = 1\n</code></pre></p> <p>Lets pick one convention : </p> <p>partition_a + partition_b = (m+n) //2</p> <p>Now for the binary search:</p> <p>It makes sense to binary search on the smaller array. Lets call this array A and the partition on it,  partition_a.</p> <p>For each partition_a we ask is left_b &gt; partition_a. If this is TRUE, then partition_a cannot be the pivot and needs to be moved right i.e. made larger.</p> <pre><code> INIT:         \n [ 1  3  4  5   6  ]\n  [ 2  6  7   8   ] \n    lo          hi\nITER 1:\n [1  3  4  5  6  ]\n        *            #left_b is 3.\n  [ 2 6 7  8 ]  \n   lo   *            #3 &gt; 7 is F; this could be the right partition_a ; hi = mid\n       F/hi\nITER 2 :\n [1  3  4  5  6  ]\n           *\n  [ 2  6 7  8 ]\n   lo  *           #4&gt; 6 is F  ; this could be partition_a hi = mid            \n      F/hi\nITER 3 :\n [1  3  4  5  6  ]\n              *\n  [ 2    6  7  8 ]\n    *              #5&gt;2 T; This cannot be the right partition_a ;\n    T/lo hi        #lo = mid+1  ; loop exits in next iteration\nITER 5 :\n[2     6   7   8]\n       *\n       F/lo,hi\nlo = hi = 1 and loop exits\n</code></pre> <p>Binary search will converge on first false value. <pre><code>   [1    3    4     |5    6  ]\n     [2     |6    7    8]\n      T     F    F    F\n</code></pre></p> <p>In our binary search we need a function move_right which simply returns left_b &gt; right_a</p> <p>Thats it. Once , we have the right partition, calculate mean:</p> <p>If (m+n) is odd : return min(right_a, right_b)</p> <p>If (m+n) is even : return (max(left_a, left_b) + min(right_a, right_b)) /2 </p>"},{"location":"iterative/2_binary_search/problems/median_of_two_sorted_arrays/LC_4__median_of_two_sorted_arrays/#code","title":"Code","text":"<pre><code>class Solution:\n    def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -&gt; float:\n        # A is always the smaller array\n        A, B = nums1, nums2 \n        if len(A) &gt; len(B) :\n            A , B = B, A\n\n        #measure their lengths    \n        m,n = len(A), len(B)\n\n        def find_partition_b(partition_a) : \n            return (m+n)//2 - partition_a\n\n        def get_left(partition,array) :\n            return float('-inf') if (partition-1 )&lt;0 else array[partition-1]\n\n        def get_right(partition,array) :\n            return float('inf') if (partition)&gt;= len(array) else array[partition]\n\n        def move_right(partition_a) : \n            partition_b = find_partition_b(partition_a)\n            left_b = get_left(partition_b,B)\n            right_a = get_right(partition_a,A)\n            return left_b &gt; right_a\n\n        #binary search to find the correct partition_a\n        lo, hi  = 0 , len(A)\n        while lo &lt; hi :\n            partition_a = (lo +hi) // 2\n            if move_right(partition_a) :\n                lo = partition_a+1\n            else :\n                hi = partition_a\n\n        #lo and hi have converged on the correct partition_a \n        partition_a,partition_b   = lo, find_partition_b(lo)\n        right_a = get_right(partition_a,A)\n        right_b = get_right(partition_b,B)\n\n        #combined array length is odd\n        if (m+n) % 2 == 1 :\n            return min(right_a,right_b)\n\n        #combined array length is even    \n        left_a = get_left(partition_a,A)\n        left_b = get_left(partition_b,B)\n        return ( max(left_a,left_b) + min(right_a,right_b) ) / 2        \n</code></pre>"},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/","title":"Properties of Comparison Based Sorting Algorithms","text":""},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/#quicksort","title":"Quicksort","text":"<p>Not Stable, Not adaptive. In-Place. O(NlogN) Average Case. </p> <p>Pivot Selection and partitioning schemes affect Complexity in a major way. </p> <p>Pivot Selection : Fixed at hi or lo (worst), random (Good enough in practicw), Median of three, etc. </p> <p>Partitoning  :  Two way partitioning ( Eg. Hoare Partitioning with weak condition) , Three way partitioning (Eg : Djikstra) , Dual Pivot partitioning.  </p> <p>Quicksort is a highly reaearched algorithm and there are many variations and derivatives. It is more like a family of algorithms. </p> <p>Can degrade to O(n^2) in cases for duplicate keys and sorted inputs, depending on pivot selection and partitioning scheme.</p> <p>Important thing to note, The most common partitioning scheme found on the internet (Lomuto parition) performs more swaps than Hoare partition with a weak condition. Also, it degrades to O(n^2) when all elements are the same ( Hoare partition with a strict condition will also degrade to O(n^2) for duplicate keys).   </p> <p>Lomuto was popularized by Bentley in the book Programming Pearls because he found Hoare difficult and unintuitve. One advantage to note: because Lomuto uses two forward iterators, it can be used on singly linked lists.</p>"},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/#mergesort","title":"Mergesort","text":"<p>In-place. Stable. Not adaptive. Not In-place (Needs extra space) . O(NlogN) worst case. Can be combined with Insertion sort for small subproblem sizes.</p>"},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/#bubble-sort","title":"Bubble Sort","text":"<p>Stable. Can be made adaptive (just add a flag to tell if a swap has occurred. If not exit early). </p> <p>Invariant for inner loop</p> <p>[ | ]   j <pre><code>def optimized_bubble_sort(arr):\n    n = len(arr)\n    for i in range(n - 1):\n        swapped = False  # Flag for no swaps in a pass\n        for j in range(n - i - 1):\n            if arr[j] &gt; arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swapped = True  # Swap occurred\n        if not swapped:\n            return  # Already sorted, no more passes needed\n    return arr\n</code></pre></p>"},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/#insertion-sort","title":"Insertion Sort","text":"<p>Quadratic. In-place. Stable. Adaptive.</p> <pre><code>def insertion_sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i-1\n        while j &gt;= 0 and key &lt; arr[j]:\n            arr[j+1] = arr[j]\n            j -= 1\n        arr[j+1] = key\n</code></pre> <p>This is quite similar to optimized bubble sort except that in bubble sort,the sort element (maximimum) is bubbled into unsorted section while in insertion sort, the sort element (minimum) is bubbled into the sorted section. </p> <p>Insertion sort is ONLINE. Each new element can be put in its sorted place as it is received.</p> <p>Shell Sort is a faster variation of Insertion sort (named after D.L. Shell who invented it). It uses insertion sort on periodic subarrays.</p> <p>Alse see :  https://stackoverflow.com/questions/47712062/how-to-distinguish-online-and-offline-sorting-algorithms</p> <p>https://cs.stackexchange.com/questions/55012/what-is-the-fastest-online-sorting-algorithm</p>"},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/#selection-sort","title":"Selection Sort","text":"<p>Quadratic. In-Place. Not Stable. Not Adaptive. </p> <p>Only advantage over insertion sort : performs less swaps than insertion sort.</p>"},{"location":"iterative/3_Sorting/properties_of_comparison_based_sorting_algorithms/#additional-references","title":"Additional References","text":"<p>https://www.toptal.com/developers/sorting-algorithms</p>"},{"location":"recursive/1_basics/","title":"Basic Recursion","text":"<p>Understand what happens when you \"do\" something before the recursive call (preorder position) or after the recursive call (postorder position). Debug this and see what is happening on the stack and how function calls are stacked and unwound.</p>"},{"location":"recursive/1_basics/TEST/","title":"TEST","text":"<p>This is a test</p>"},{"location":"recursive/2_backtracking/","title":"Bactracking","text":"<p>Backtracking seems and difficult to learn, because there are so many different ways of doing the same thing.</p> <p>Here, we solve the same problem in many different ways only to see the possibilities.</p>"}]}